{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor, Resize\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import ray\n",
    "\n",
    "\n",
    "from fastai2.vision.all import *\n",
    "\n",
    "from fastai2.metrics import RocAuc\n",
    "from fastai2.vision.all import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize images to make dataloader faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Image sizes are large. Dataloaders spend a lot of time loading them.\n",
    "Meaning training loop.\n",
    "\n",
    "One way to make this faster is to save images as resized torch tensors.\n",
    "Then load from these serialized objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paths(img_folder, tensor_folder):\n",
    "    \n",
    "    '''\n",
    "    img_folder = folder in which images are stored\n",
    "    tensor_folder = where to save the tensors\n",
    "    resize_shape = resize shape of tensors\n",
    "    num_cpus = num_cpus to use in parallel with ray\n",
    "    \n",
    "    '''\n",
    "\n",
    "    if not os.path.exists(tensor_folder):\n",
    "        os.makedirs(tensor_folder)\n",
    "\n",
    "    image_fns = os.listdir(img_folder)\n",
    "    image_paths = [os.path.join(img_folder, elem) for elem in image_fns]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    file_ext = image_fns[0].split('.')[-1]\n",
    "    print(f'file_ext identified  = {file_ext}')\n",
    "\n",
    "    dest_fns = [x.split('.')[0]+'.pt' for x in image_fns]\n",
    "    dest_paths = [os.path.join(tensor_folder, elem) for elem in dest_fns]\n",
    "    \n",
    "    return image_paths, dest_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2tensor(a,b, resize_shape = (512,512)):\n",
    "    to_tensor = ToTensor()\n",
    "    resize_func = Resize(size = resize_shape)\n",
    "    image = Image.open(a)\n",
    "    torch.save(to_tensor(resize_func(image))\n",
    "                                        , b)\n",
    "    image.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder = 'data/jpeg/train'\n",
    "tensor_folder = 'data/tensor-224'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = create_paths(img_folder, tensor_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with multiprocessing.Pool(processes=10) as pool:\n",
    "    results = pool.starmap(partial(img2tensor, resize_shape=(224,224))\n",
    "    , zip(a, b) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom datasets into fastai2 dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df.index,train_df.target.values, \n",
    "                                                  test_size=0.33,\n",
    "                                                 random_state=42)\n",
    "\n",
    "train_df['use'] = ''\n",
    "\n",
    "train_df.loc[X_train, 'use'] = 'train'\n",
    "train_df.loc[X_val, 'use'] = 'val'\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "train_df.use.value_counts()\n",
    "\n",
    "train_df[train_df.use=='train'].target.value_counts(normalize=True)\n",
    "\n",
    "train_df[train_df.use=='val'].target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelanomaDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, use, tfms):\n",
    "        # use = 'train' or val\n",
    "        # tfms = transformations\n",
    "        self.use = use\n",
    "        self.df = train_df[train_df.use==use]\n",
    "        self.df.reset_index(inplace=True)\n",
    "        self.tfms = tfms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_fn = self.df.iloc[idx]['image_name'].split('.')[0] + '.pt'\n",
    "        img = torch.load(f'data/tensor-224/{img_fn}')\n",
    "        img = F.interpolate(img, size=224)\n",
    "        if self.tfms:  # transformation\n",
    "            img = self.tfms(img)\n",
    "        if self.use in ['train', 'val']:\n",
    "            target = np.array([self.df.iloc[idx]['target']])\n",
    "            target = torch.tensor(target, dtype=torch.float32)\n",
    "            return (img, target)\n",
    "\n",
    "        elif self.use=='test':\n",
    "            return (img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "tfms = transforms.Compose([transforms.Resize(size = (224,224))])\n",
    "\n",
    "train_dataset = MelanomaDataset(use='train', tfms = None)\n",
    "\n",
    "val_dataset = MelanomaDataset(use='val', tfms = None)\n",
    "\n",
    "dls = DataLoaders.from_dsets(train_dataset, val_dataset,bs=32)\n",
    "\n",
    "dls_large = DataLoaders.from_dsets(train_dataset, val_dataset,bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "output = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, n_out = 1, \n",
    "                    loss_func=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(num_it=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, n_out = 1, \n",
    "                    loss_func=loss_fn, metrics = [RocAuc()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(3, 3e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
